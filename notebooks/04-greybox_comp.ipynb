{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "\n",
    "## Library import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-16T14:44:50.874881Z",
     "start_time": "2019-06-16T14:44:38.616867Z"
    }
   },
   "outputs": [],
   "source": [
    "# Data manipulation\n",
    "# ==============================================================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Visualization\n",
    "# ==============================================================================\n",
    "import plotly.graph_objs as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Stattiscals tests\n",
    "# ==============================================================================\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "\n",
    "# from statsmodels.graphics.tsaplots import plot_pacf\n",
    "\n",
    "# GreyBox [own package]\n",
    "# ==============================================================================\n",
    "from greyboxmodel.model import DarkGreyModel, Ti, TiTe, TiTh, TiTeTh, TiTeThRia\n",
    "from greyboxmodel.fit import darkgreyfit\n",
    "\n",
    "# Warnings\n",
    "# ==============================================================================\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Autoreload extension\n",
    "# ==============================================================================\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local functions\n",
    "# ==============================================================================\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "def rmse(*args, **kwargs):\n",
    "    return mean_squared_error(*args, **kwargs) ** 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Data import\n",
    "We retrieve all the required data for the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ph</th>\n",
       "      <th>Ti</th>\n",
       "      <th>Ta</th>\n",
       "      <th>Th</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-12-23 00:00:00+00:00</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>18.1375</td>\n",
       "      <td>5.4</td>\n",
       "      <td>4.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-23 01:00:00+00:00</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>18.1000</td>\n",
       "      <td>5.1</td>\n",
       "      <td>4.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-23 02:00:00+00:00</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>18.0125</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-23 03:00:00+00:00</th>\n",
       "      <td>97.223561</td>\n",
       "      <td>17.9625</td>\n",
       "      <td>4.8</td>\n",
       "      <td>4.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-23 04:00:00+00:00</th>\n",
       "      <td>76.202250</td>\n",
       "      <td>17.9875</td>\n",
       "      <td>5.5</td>\n",
       "      <td>68.15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Ph       Ti   Ta     Th\n",
       "2019-12-23 00:00:00+00:00   0.000000  18.1375  5.4   4.60\n",
       "2019-12-23 01:00:00+00:00   0.000000  18.1000  5.1   4.45\n",
       "2019-12-23 02:00:00+00:00   0.000000  18.0125  5.0   4.15\n",
       "2019-12-23 03:00:00+00:00  97.223561  17.9625  4.8   4.10\n",
       "2019-12-23 04:00:00+00:00  76.202250  17.9875  5.5  68.15"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Duration of a record\n",
    "# ==============================================================================\n",
    "rec_duration = 1 # hour\n",
    "\n",
    "# Loading temperature Data\n",
    "# ==============================================================================\n",
    "input_df = pd.read_csv('../data/demo_data.csv', index_col=0, parse_dates=True)\n",
    "input_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read some demo data.  \n",
    "* Ph: Heating system power output\n",
    "* Ta: Ambient temperature\n",
    "* Ti: Internal temperature\n",
    "\n",
    "We are also setting a set of custom fields in our input data: `Ti0`, `Th0` and `Te0`. These fields define the initial conditions for `Ti`, `Th` and `Te` for each record of the input data respectively. E.g. if a sub-model is trained based on the 10-20 records of the training data, the initial conditions for the above params will be set by the 10. record of the input data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input X shape: (792, 5), input y shape: (792,)\n"
     ]
    }
   ],
   "source": [
    "# Setting the initial conditions\n",
    "# ==============================================================================\n",
    "input_df['Ti0'] = input_df['Ti']\n",
    "input_df['Th0'] = input_df['Ti']\n",
    "input_df['Te0'] = input_df['Ti'] - 2\n",
    "\n",
    "input_X = input_df[['Ph', 'Ta', 'Ti0', 'Te0', 'Th0']]\n",
    "input_y = input_df['Ti']\n",
    "\n",
    "print(f'Input X shape: {input_X.shape}, input y shape: {input_y.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: X shape: (672, 5), y shape: (672,)\n",
      "Test: X shape: (120, 5), y shape: (120,)\n"
     ]
    }
   ],
   "source": [
    "# Splitting the data into train and test\n",
    "# ==============================================================================\n",
    "X_train, X_test, y_train, y_test = train_test_split(input_X, input_y, test_size=5 / 33, shuffle=False)\n",
    "\n",
    "print(f'Train: X shape: {X_train.shape}, y shape: {y_train.shape}')\n",
    "print(f'Test: X shape: {X_test.shape}, y shape: {y_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up the model training parameters for each model instance that we want to spin up in the pipeline.  \n",
    "\n",
    "The `Ti0` param is the initial condition for the internal temperature at t=0 - this is set to the first record of `X_train['Ti0']` as described above and is fixed, hence `vary: False`.  \n",
    "\n",
    "The `Te0` param is the initial condition for the building envelope temperature at t=0 - - this is set to the first record of `X_train['Te0']` as described above and is NOT fixed, hence `vary: True`.  \n",
    "\n",
    "The `Th0` param is the initial condition for the heating system temperature at t=0 - - this is set to the first record of `X_train['Th0']` as described above and is NOT fixed, hence `vary: True`.  \n",
    "\n",
    "`Ci`, `Ce`, `Rie` and `Ria` params are the initial conditions for these thermal parameters. As these will be fit by the model training their default is `vary: True`. The values for these params' initial conditions are set arbitrarily to `1` it is assumed that no estimates have been calculated for them (e.g. based on building physical properties).\n",
    "\n",
    "Note that we've added the `Ch` and `Rih` params with set initial conditions not allowed to vary. These are the RC params for the heating system and their values have been precalculated from the heating system's time constant to make this example simpler.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_params_Ti = {\n",
    "    'Ti0': {'value': X_train.iloc[0]['Ti0'], 'vary': False},\n",
    "    'Ci': {'value': 1},\n",
    "    'Ria': {'value': 1},\n",
    "}\n",
    "\n",
    "train_params_TiTe = {\n",
    "    'Ti0': {'value': X_train.iloc[0]['Ti0'], 'vary': False},\n",
    "    'Te0': {'value': X_train.iloc[0]['Ti0'], 'vary': True},\n",
    "    'Ci': {'value': 1},\n",
    "    'Ce': {'value': 1},\n",
    "    'Rie': {'value': 1},\n",
    "    'Rea': {'value': 1},\n",
    "}\n",
    "\n",
    "train_params_TiTh = {\n",
    "    'Ti0': {'value': X_train.iloc[0]['Ti0'], 'vary': False},\n",
    "    'Th0': {'value': X_train.iloc[0]['Th0'], 'vary': False},\n",
    "    'Ci': {'value': 1},\n",
    "    'Ch': {'value': 2.55, 'vary': False},\n",
    "    'Ria': {'value': 1},\n",
    "    'Rih': {'value': 0.65, 'vary': False}\n",
    "}\n",
    "\n",
    "train_params_TiTeTh = {\n",
    "    'Ti0': {'value': X_train.iloc[0]['Ti0'], 'vary': False},\n",
    "    'Te0': {'value': X_train.iloc[0]['Te0'], 'vary': True, 'min': 10, 'max': 25},\n",
    "    'Th0': {'value': X_train.iloc[0]['Th0'], 'vary': False},\n",
    "    'Ci': {'value': 1},\n",
    "    'Ch': {'value': 2.55, 'vary': False},\n",
    "    'Ce': {'value': 1},\n",
    "    'Rie': {'value': 1},\n",
    "    'Rea': {'value': 1},\n",
    "    'Rih': {'value': 0.65, 'vary': False}\n",
    "}\n",
    "\n",
    "train_params_TiTeThRia = {\n",
    "    'Ti0': {'value': X_train.iloc[0]['Ti0'], 'vary': False},\n",
    "    'Te0': {'value': X_train.iloc[0]['Te0'], 'vary': True, 'min': 10, 'max': 25},\n",
    "    'Th0': {'value': X_train.iloc[0]['Th0'], 'vary': False},\n",
    "    'Ci': {'value': 1},\n",
    "    'Ch': {'value': 2.55, 'vary': False},\n",
    "    'Ce': {'value': 1},\n",
    "    'Rie': {'value': 1},\n",
    "    'Rea': {'value': 1},\n",
    "    'Ria': {'value': 1},\n",
    "    'Rih': {'value': 0.65, 'vary': False}\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up our initial conditions parameters map for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ic_params_map = {\n",
    "    'Ti0': lambda X_test, y_test, train_result: y_test.iloc[0],\n",
    "    'Th0': lambda X_test, y_test, train_result: y_test.iloc[0],\n",
    "    'Te0': lambda X_test, y_test, train_result: train_result.var['Te'][-1],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can instantiate a range of models to be evaluated - in this case we are setting up 5 different models starting from the simplest `Ti` to `TiTeThRia` with medium complexity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    Ti(train_params_Ti, rec_duration),\n",
    "    TiTe(train_params_TiTe, rec_duration),\n",
    "    TiTh(train_params_TiTh, rec_duration),\n",
    "    TiTeTh(train_params_TiTeTh, rec_duration),\n",
    "    TiTeThRia(train_params_TiTeThRia, rec_duration)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to split our training data set into managable chunks for the prefit stage. `Sklearn` is quite helpful here again, in case we wanted to define the prefit sets to be 1 day (24 hours) long:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefit_splits = KFold(n_splits=int(len(X_train) / 24), shuffle=False).split(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To evaluate the performance of our models we will need to define an error metric. Again, there is a wide range of options available from `sklearn`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_metric = rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can define a prefit \"survival threshold\" to trim the number of model fits during the training process. Any models achieving a higher error during the prefit stage will not make it into the training stage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefit_filter = lambda error: abs(error) < 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Under the hood, `DarkGreyBox` uses `lmfit.minimize` to fit the thermal model parameters to the training data by passing it a custom objective function defined by the model class. The fit method used by `lmfit.minimize` can be customised as well, and while the standard Nelder-Mead and Levenberg-Marquardt methods work well in general, it is worth experimenting with others (see here for a list of supported methods: https://lmfit.github.io/lmfit-py/fitting.html#fit-methods-table)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "method = 'nelder'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting up is ready! We only need to call the `darkgreyfit` convenience pipeline function that delegates the work to the prefit, train and test low-level procedures running on multiple processes and reducing / cleaning the interim results. The returned `pandas.DataFrame` contains the fit models and their train/test performance evaluation.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:    1.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    1.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:    1.7s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of   7 | elapsed:    3.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed:    3.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:    4.7s remaining:    0.0s\n"
     ]
    }
   ],
   "source": [
    "df = darkgreyfit(\n",
    "    models,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    X_test,\n",
    "    y_test,\n",
    "    ic_params_map,\n",
    "    error_metric=error_metric,\n",
    "    prefit_splits=prefit_splits,\n",
    "    prefit_filter=prefit_filter,\n",
    "    reduce_train_results=True,\n",
    "    method=method,\n",
    "    n_jobs=-1,\n",
    "    verbose=10\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this specific example:\n",
    "* *Initial Population:* 5 model structures were prefit to 28x 24-hour data chunks resulting in 140 pipelines\n",
    "* *Fitness Function:* The RMSE of a prefit had to be < 2ËšC to survive\n",
    "* *Selection:* 110 pipelines survived the prefit selection and made it into training on the entire training set \n",
    "* (No *Crossover* or *Mutation*)\n",
    "* *Termination:* Out of the 110 pipelines trained, 11 distinct model results were found (i.e. many pipelines were arriving at the same parameter set results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can select the model with the lowest error and display its params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[select_idx, (['train', 'test'], 'model_result')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_idx = df[('train', 'error')].argmin()\n",
    "\n",
    "model, error_train = df.loc[select_idx, ('train', ['model', 'error'])]\n",
    "error_test = df.loc[select_idx, ('test', 'error')]\n",
    "train_results, test_results = df.loc[select_idx, (['train', 'test'], 'model_result')]\n",
    "\n",
    "print(f'\\t\\tTrain error: {error_train}')\n",
    "model.result.params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results show that the `TiTeThRia` model has a good fit on the training set (R2=0.9612) and the errors are low for both the training and test sets (RMSE 0.3719 and 0.3383 respectively) indicating that the model generalises well for data it hasn't seen before (no overfitting problem)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting Train results\n",
    "# ==============================================================================\n",
    "fig = make_subplots(rows=1, cols=2, vertical_spacing=0.02, subplot_titles=(f'RMSE: {error_train}', ''))\n",
    "\n",
    "fig.add_trace(go.Scatter(x=y_train.index, y=y_train, name='Ti Measured', mode='lines'), row=1, col=1)\n",
    "for i, (key, value) in enumerate(train_results.var.items()):\n",
    "    fig.add_trace(go.Scatter(x=y_train.index, y=value, name=f\"{key} Modelled\", mode='lines'), row=1, col=1)\n",
    "\n",
    "# Plotting residuals\n",
    "fig.add_trace(go.Scatter(x=y_train.index, y=y_train - train_results.Z, name='Residuals', mode='markers', marker=dict(color='black', opacity=0.5)), row=1, col=2)\n",
    "\n",
    "fig.update_layout(title_text=f\"Model: {model.__class__.__name__} - Train\")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting Test results\n",
    "# ==============================================================================\n",
    "fig = make_subplots(rows=1, cols=2, vertical_spacing=0.02, subplot_titles=(f'RMSE: {round(error_test, 2)}', ''))\n",
    "\n",
    "fig.add_trace(go.Scatter(x=y_test.index, y=y_test, name='Ti Measured', mode='lines'), row=1, col=1)\n",
    "for i, (key, value) in enumerate(test_results.var.items()):\n",
    "    fig.add_trace(go.Scatter(x=y_test.index, y=value, name=f\"{key} Modelled\", mode='lines'), row=1, col=1)\n",
    "\n",
    "# Plotting residuals\n",
    "fig.add_trace(go.Scatter(x=y_test.index, y=y_test - test_results.Z, name='Residuals', mode='markers', marker=dict(color='black', opacity=0.5)), row=1, col=2)\n",
    "\n",
    "fig.update_layout(title_text=f\"Model: {model.__class__.__name__} - Test\")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "We report here relevant references:\n",
    "1. author1, article1, journal1, year1, url1\n",
    "2. author2, article2, journal2, year2, url2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "envPiazzi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "8732f7fe51935d13b87c011f0c0f53df79204322a91ea60719a47c26248d0000"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
